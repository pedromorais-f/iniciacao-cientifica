{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f42f290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-26T03:31:05.768146Z",
     "start_time": "2023-05-26T03:31:05.734944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#Getting the train's data and test's data\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "data_train = MNIST(root=\"./\", download=True, train=True, transform=transform)\n",
    "data_test = MNIST(root=\"./\", download=True, train=False, transform=transform)\n",
    "\n",
    "print(data_train.data.size())\n",
    "print(data_test.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d788ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-26T03:31:12.441777Z",
     "start_time": "2023-05-26T03:31:12.438513Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setting a variable to work with GPU\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c6b570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-26T03:31:12.962880Z",
     "start_time": "2023-05-26T03:31:12.958464Z"
    }
   },
   "outputs": [],
   "source": [
    "#Loading data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loaded = DataLoader(data_train, batch_size=32, shuffle=True)\n",
    "test_loaded = DataLoader(data_test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6099b129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-26T03:57:37.196166Z",
     "start_time": "2023-05-26T03:57:37.191475Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating MNIST model\n",
    "from torch import nn\n",
    "\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistModel, self).__init__()\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            #CONV1\n",
    "            nn.Conv2d(1, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            #CONV2\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(32*5*5, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d9f7060d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-26T03:57:38.032095Z",
     "start_time": "2023-05-26T03:57:38.023402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (linear_layers): Sequential(\n",
       "    (0): Linear(in_features=800, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Putting the MnistModel into a variable\n",
    "model = MnistModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b174e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining an optimizer and loss\n",
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2a8157f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Epoch1: 1875it [01:14, 25.23it/s]\n",
      "Validating the model: 313it [00:08, 34.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5   Training loss: 0.2263   Testing loss: 0.1077   Train accuracy: 0.9289   Test accuracy: 0.9674  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Epoch2: 1875it [01:11, 26.38it/s]\n",
      "Validating the model: 313it [00:08, 35.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/5   Training loss: 0.1141   Testing loss: 0.0879   Train accuracy: 0.9663   Test accuracy: 0.9731  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Epoch3: 1875it [01:12, 25.77it/s]\n",
      "Validating the model: 313it [00:08, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5   Training loss: 0.1050   Testing loss: 0.1086   Train accuracy: 0.9694   Test accuracy: 0.9702  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Epoch4: 1875it [01:12, 25.72it/s]\n",
      "Validating the model: 313it [00:08, 37.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5   Training loss: 0.1000   Testing loss: 0.0978   Train accuracy: 0.9705   Test accuracy: 0.9706  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Epoch5: 1875it [01:12, 25.90it/s]\n",
      "Validating the model: 313it [00:09, 34.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/5   Training loss: 0.1005   Testing loss: 0.0900   Train accuracy: 0.9707   Test accuracy: 0.9712  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "from tqdm import tqdm\n",
    "#Defining the numbers of epochs\n",
    "epochs = 5\n",
    "\n",
    "#Lists to get all the data about training\n",
    "train_loss, test_loss = [], []\n",
    "accuracy_train, accuracy_test = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_train_loss = 0\n",
    "    total_test_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    total = 0\n",
    "    for index, (image, label) in tqdm(enumerate(train_loaded), desc=f\"Fitting Epoch{epoch + 1}\"):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(image)\n",
    "        \n",
    "        loss = criterion(pred, label)\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = nn.functional.softmax(pred, dim=1)\n",
    "        for i, p in enumerate(pred):\n",
    "            if label[i] == torch.max(p.data, 0)[1]:\n",
    "                total = total + 1\n",
    "    \n",
    "    train_accuracy = total / len(data_train)\n",
    "    total_train_loss = total_train_loss / (index + 1)\n",
    "    \n",
    "    accuracy_train.append(train_accuracy)\n",
    "    train_loss.append(total_train_loss)\n",
    "    \n",
    "    #Validating the model\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    for index, (image, label) in tqdm(enumerate(test_loaded), desc=\"Validating the model\"):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        pred = model(image)\n",
    "        \n",
    "        loss = criterion(pred, label)\n",
    "        total_test_loss += loss.item()\n",
    "        \n",
    "        pred = nn.functional.softmax(pred, dim=1)\n",
    "        for i, p in enumerate(pred):\n",
    "            if label[i] == torch.max(p.data, 0)[1]:\n",
    "                total = total + 1\n",
    "    test_accuracy = total / len(data_test)\n",
    "    total_test_loss = total_test_loss / (index + 1)\n",
    "    \n",
    "    accuracy_test.append(test_accuracy)\n",
    "    test_loss.append(total_test_loss)\n",
    "    \n",
    "    print(\"Epoch: {}/{}  \".format(epoch + 1, epochs),\n",
    "            \"Training loss: {:.4f}  \".format(total_train_loss),\n",
    "            \"Testing loss: {:.4f}  \".format(total_test_loss),\n",
    "            \"Train accuracy: {:.4f}  \".format(train_accuracy),\n",
    "            \"Test accuracy: {:.4f}  \".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3f00be3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "#Saving the model and the model parameters\n",
    "torch.save(model.state_dict(),\"../Pytorch/Model/model_dict\")\n",
    "torch.save(model, \"../Pytorch/Model/model.pt\")\n",
    "print(\"Model Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
